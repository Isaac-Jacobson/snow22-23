{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "StreakDetector",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Isaac-Jacobson/snow/blob/main/fallspeedStuff/notebooks/StreakDetector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Snowflake Streak Detector"
      ],
      "metadata": {
        "id": "R13NHesM1bRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Bonus cell just for executing linux commands on collab\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WiJKNB-Y1Yrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Setup"
      ],
      "metadata": {
        "id": "TbZSNoQ31n84"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhl8lqVamEty"
      },
      "source": [
        "#Install dependecies\n",
        "\n",
        "!pip uninstall opencv-python-headless==4.5.5.62 \n",
        "!pip install opencv-python-headless==4.1.2.30\n",
        "!pip install -q tflite-model-maker\n",
        "!pip install -q tflite-support\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Needed imports although matplotlib, numpy,and pandas aren't currently used but will probably be needed\n",
        "import tensorflow as tf\n",
        "\n",
        "from tflite_model_maker.config import ExportFormat\n",
        "from tflite_model_maker import model_spec\n",
        "from tflite_model_maker import object_detector\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib as plt\n",
        "\n",
        "import os\n",
        "from os import listdir\n",
        "import cv2\n",
        "from cv2 import threshold\n",
        "from cv2 import HoughLines\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from skimage import measure\n",
        "import math\n",
        "import scipy\n"
      ],
      "metadata": {
        "id": "899Xah1s-PVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Get the data and base model"
      ],
      "metadata": {
        "id": "l9SrNd3b2Suu"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtdZ-JDwMimd"
      },
      "source": [
        "#Picking what base model to use, efficientdet is just a starting place\n",
        "#spec = model_spec.get('efficientdet_lite0')\n",
        "#spec = model_spec.get('efficientdet_lite2')\n",
        "spec = model_spec.get('efficientdet_lite4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get dat data\n",
        "#!curl -L \"https://app.roboflow.com/ds/fosD79eC34?key=xH3OhXG8fK\" > data.zip\n",
        "#!unzip data.zip; rm data.zip\n",
        "#!curl -L \"https://app.roboflow.com/ds/1XRSjPxvAk?key=B8s0tsnsPH\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip\n",
        "#!curl -L \"https://app.roboflow.com/ds/RQYEC5i0Na?key=djTi5csoOX\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip\n",
        "!curl -L \"https://app.roboflow.com/ds/7NzUVnpDY1?key=Dnyi0VIAMR\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip"
      ],
      "metadata": {
        "id": "UrHyUD4voZq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#I'm working on automating the jpeg and csv manipulation but right now I still hand format the csv\n",
        "\n",
        "#!mkdir data\n",
        "!mv ./test/*.jpg .\n",
        "!mv ./train/*.jpg .\n",
        "!mv ./valid/*.jpg .\n",
        "!rm ./test/*.csv\n",
        "!rm ./train/*.csv\n",
        "!rm ./valid/*.csv\n",
        "!rmdir ./test \n",
        "!rmdir ./train \n",
        "!rmdir ./valid\n",
        "\n",
        "#!rm ./merged.csv\n",
        "#!head -n 1 ./annotation/train.csv > merged.csv && tail -n+2 -q ./annotation/*.csv >> merged.csv"
      ],
      "metadata": {
        "id": "U1VSEsVvqwJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pre Processing\n",
        "Binarize all the images before training"
      ],
      "metadata": {
        "id": "8pX_kWgLoLiN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bg = cv2.imread('Flake000016_Cam1_2_2022-1-28-23-43-5-821.png')\n",
        "#fg = cv2.imread('Flake01.png')\n",
        "cv2_imshow(bg)\n",
        "#cv2_imshow(fg)"
      ],
      "metadata": {
        "id": "hW3ceYd7yOUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#processes the image, saves it as a png, lots of thresholds!!!\n",
        "def simplify(img, background, cnt=0):\n",
        "  #background subtraction\n",
        "  smpImg = cv2.subtract(img, bg)\n",
        "  print(\"subtraction:\")\n",
        "  cv2_imshow(smpImg)\n",
        "\n",
        "  #Binarize the image\n",
        "  ret1, binImg1 = threshold(smpImg, 20, 225, cv2.THRESH_BINARY)\n",
        "  print(\"binarized 1:\")\n",
        "  cv2_imshow(binImg1)\n",
        "  #blur groups of pixels into blobs\n",
        "  blur = cv2.GaussianBlur(binImg1,(19,19),0)\n",
        "  print(\"Blurred:\")\n",
        "  cv2_imshow(blur)\n",
        "  #binarize the image again\n",
        "  ret1, binImg2 = threshold(blur, 150, 255, cv2.THRESH_BINARY)\n",
        "  print(\"binarized 2:\")\n",
        "  cv2_imshow(binImg2)\n",
        "  #save it to a png\n",
        "  #filename = \"./flake\" + str(cnt)\n",
        "  cv2.imwrite(\"testFlake\", binImg2)"
      ],
      "metadata": {
        "id": "UV7BNHhnpJ7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simplify(fg, bg)"
      ],
      "metadata": {
        "id": "raIjhHh9lKxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_dir = \".\"\n",
        "count = 0;\n",
        "for image in os.listdir(folder_dir):\n",
        "  if (image.endswith(\".png\")):\n",
        "    count += 1\n",
        "    simplify(image, bg, count)"
      ],
      "metadata": {
        "id": "qnaDUhWwoSGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train and test"
      ],
      "metadata": {
        "id": "st34ytea2X8R"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HD5BvzWe6YKa"
      },
      "source": [
        "train_data, validation_data, test_data = object_detector.DataLoader.from_csv('./annotations.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_data.label_map)\n",
        "\n",
        "#Output should be: {1: 'class', 2: 'Streak'} if not check the annotations file"
      ],
      "metadata": {
        "id": "7q0505gI39x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwlYdTcg63xy"
      },
      "source": [
        "# train_whole_model, controls layers being trained, setting to false uses transfer learning to train and\n",
        "# only trains layers that don't match model_spec.config.var_freeze_expr.\n",
        "model = object_detector.create(train_data, model_spec=spec, epochs = 12, batch_size=5, train_whole_model=True, validation_data=validation_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "#There should be 15,108,198 parameters if using lite4"
      ],
      "metadata": {
        "id": "jNayYrKp3Suj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test"
      ],
      "metadata": {
        "id": "vDIhcO_w2gQR"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xmnl6Yy7ARn"
      },
      "source": [
        "#Needs a bigger test set\n",
        "\n",
        "#Prints mAP for whole model and specifically for each piece (class)\n",
        "model.evaluate(test_data, batch_size=1)\n",
        "#print (model.predict(test_data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Making and Testing the tflite version"
      ],
      "metadata": {
        "id": "_SwUpxN02lZZ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hm_UULdW7A9T"
      },
      "source": [
        "# Defaults to post training full integer quantization when exported to tflite file\n",
        "model.export(export_dir='.')\n",
        "\n",
        "#You can download the model this way"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHYDWcljr6jq"
      },
      "source": [
        "#Prints mAP for whole model and specifically for each piece (class)\n",
        "model.evaluate_tflite('model.tflite419', test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Bounding Box based Slope \n",
        "not used"
      ],
      "metadata": {
        "id": "jiyJQ8k1lAyZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Count the number of pixels (above threshold) in the bottom squares of the given array\n",
        "def countPixels(arr, pixelThreshold=50, testSize=0.45):\n",
        "  cnt1 = 0\n",
        "  cnt2 = 0\n",
        "  height = len(arr)\n",
        "  width = len(arr[0])\n",
        "  square = int(min(width, height) * testSize)\n",
        "\n",
        "  for i in range(height-square, height, 1):\n",
        "    for j in range(0, square, 1):\n",
        "      if(arr[i][j][0] >= pixelThreshold): cnt1 += 1\n",
        "\n",
        "  for i in range(height-square, height, 1):\n",
        "    for j in range(width-square, width, 1):\n",
        "      if(arr[i][j][0] >= pixelThreshold): cnt2 += 1   \n",
        "\n",
        "  return cnt1, cnt2  "
      ],
      "metadata": {
        "id": "K5ydsAQ3eUvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def findBoxSlope(img, xmin, ymin, xmax, ymax, pixelThreshold=30, verticalThreshold=0.3, testSize=0.45):\n",
        "  img = img[ymin:ymax, xmin:xmax]\n",
        "  cnt1, cnt2 = countPixels(img, pixelThreshold, testSize)\n",
        "  print(\"Counts: \" + str(cnt1) + \"   \" + str(cnt2))\n",
        "  slope = (ymax-ymin)/(xmax-xmin)\n",
        "  if(cnt1 > ((1+verticalThreshold) * cnt2)):\n",
        "    #positive slope\n",
        "    return slope\n",
        "  elif(cnt2 > ((1+verticalThreshold)*cnt1)):\n",
        "    #negative slope\n",
        "    return -1*slope\n",
        "  else:\n",
        "    #vertical streak\n",
        "    return 0 #represents a vertical streak because we should never have a horizantal one"
      ],
      "metadata": {
        "id": "DJT5sHW7-7tM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sampling Slope"
      ],
      "metadata": {
        "id": "lt_7pjEAlJnT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NOT USED\n",
        "#Finds the width of a \"streak\" in the binarized array\n",
        "def findStreakWidth(arr):\n",
        "  lptr = 0\n",
        "  rptr = 0\n",
        "  flag = True\n",
        "  for i in range(0, len(arr)):\n",
        "    if(arr[i] == 1):\n",
        "      if(flag):\n",
        "        flag = False\n",
        "        lptr = i\n",
        "      rptr = i\n",
        "  return int(rptr - lptr)"
      ],
      "metadata": {
        "id": "4IYrP8_dAuW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Finds the midpoint of a streak in the binarized array with a left pointer reset after 5 dark pixels in a row\n",
        "def findMidpoint(arr):\n",
        "  lptr = 0\n",
        "  rptr = len(arr)\n",
        "  flag = True\n",
        "  cnt = 0\n",
        "  for i in range(0, len(arr)):\n",
        "    if(arr[i] == 1):\n",
        "      cnt = 0\n",
        "      if(flag):\n",
        "        flag = False\n",
        "        lptr = i\n",
        "      rptr = i\n",
        "    else:\n",
        "      if(cnt==5):\n",
        "        flag = True\n",
        "        cnt = 0\n",
        "      cnt+=1\n",
        "\n",
        "  if((lptr==0) and (rptr==len(arr))):\n",
        "    return -1\n",
        "  else:\n",
        "    return int((lptr+rptr)/2)"
      ],
      "metadata": {
        "id": "_fHHgHD67jQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Takes the list of points and finds the slope between each pair than averages the slope\n",
        "#A poor-mans line line of best fit\n",
        "def slopeFromPoints(points):\n",
        "  n = len(points)\n",
        "  cnt = 0\n",
        "  total = 0\n",
        "  for i in range(0, n-1):\n",
        "    if((points[i][0]!=-1) and (points[i+1][0]!=-1)):\n",
        "      rise = abs(points[i+1][1] - points[i][1])\n",
        "      run = abs(points[i+1][0] - points[i][0])\n",
        "      if(run != 0):\n",
        "        slope = rise/run\n",
        "      else:\n",
        "        #Vertical slope encoding ***FIX ME***\n",
        "        slope = 100\n",
        "        print(\"Vertical segment, check results!\")\n",
        "      total += slope\n",
        "    else:\n",
        "      cnt+=1\n",
        "  if(n-cnt-1 <= 0):\n",
        "    return 0\n",
        "  return total/((n-cnt)-1)"
      ],
      "metadata": {
        "id": "jwEwFPUSDrVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Binarize and FLATTEN the provided array \n",
        "def binarize(img, lower=25, upper=255):\n",
        "  newImg = []\n",
        "  for i in range(len(img)):\n",
        "    inner = []\n",
        "    for j in range(len(img[0])):\n",
        "        inner.append(0)\n",
        "    newImg.append(inner)\n",
        "  for i in range(0, len(img)):\n",
        "    for j in range(0, len(img[0])):\n",
        "      if((img[i][j][0] > upper) or (img[i][j][0] < lower)):\n",
        "        newImg[i][j] = 0\n",
        "      else:\n",
        "        newImg[i][j] = 1\n",
        "  return newImg"
      ],
      "metadata": {
        "id": "kB26_yWZSRc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Uses the n-sampling method to find the slope of the streak in the given bounding box\n",
        "def findSampleSlope(img, xmin, ymin, xmax, ymax, n=7):\n",
        "  img = img[ymin:ymax, xmin:xmax]\n",
        "  binImg = binarize(img, 25, 255)\n",
        "  midpoints = [(0,0)]*n\n",
        "  height = ymax-ymin\n",
        "  step = int(height / (n+1))\n",
        "  for i in range(0, n):\n",
        "    y = i*step\n",
        "    midpoints[i] = (findMidpoint(binImg[y][:]), y)\n",
        "  return slopeFromPoints(midpoints)"
      ],
      "metadata": {
        "id": "TTa5LP50latT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing"
      ],
      "metadata": {
        "id": "a_fshjd8lTYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "model_path = 'model419.tflite'\n",
        "\n",
        "# Load the labels into a list\n",
        "#classes = ['???'] * model.model_spec.config.num_classes\n",
        "#label_map = model.model_spec.config.label_map\n",
        "#for label_id, label_name in label_map.as_dict().items():\n",
        "#  classes[label_id-1] = label_name\n",
        "classes = ['Streak', 'Streak']\n",
        "\n",
        "# Define a list of colors for visualization\n",
        "COLORS = np.random.randint(0, 255, size=(len(classes), 3), dtype=np.uint8)\n",
        "\n",
        "def preprocess_image(image_path, input_size):\n",
        "  \"\"\"Preprocess the input image to feed to the TFLite model\"\"\"\n",
        "  img = tf.io.read_file(image_path)\n",
        "  img = tf.io.decode_image(img, channels=3)\n",
        "  img = tf.image.convert_image_dtype(img, tf.uint8)\n",
        "  original_image = img\n",
        "  resized_img = tf.image.resize(img, input_size)\n",
        "  resized_img = resized_img[tf.newaxis, :]\n",
        "  resized_img = tf.cast(resized_img, dtype=tf.uint8)\n",
        "  return resized_img, original_image\n",
        "\n",
        "\n",
        "def detect_objects(interpreter, image, threshold):\n",
        "  \"\"\"Returns a list of detection results, each a dictionary of object info.\"\"\"\n",
        "\n",
        "  signature_fn = interpreter.get_signature_runner()\n",
        "\n",
        "  # Feed the input image to the model\n",
        "  output = signature_fn(images=image)\n",
        "\n",
        "  # Get all outputs from the model\n",
        "  count = int(np.squeeze(output['output_0']))\n",
        "  scores = np.squeeze(output['output_1'])\n",
        "  classes = np.squeeze(output['output_2'])\n",
        "  boxes = np.squeeze(output['output_3'])\n",
        "\n",
        "  results = []\n",
        "  for i in range(count):\n",
        "    if scores[i] >= threshold:\n",
        "      result = {\n",
        "        'bounding_box': boxes[i],\n",
        "        'class_id': classes[i],\n",
        "        'score': scores[i]\n",
        "      }\n",
        "      results.append(result)\n",
        "  return results\n",
        "\n",
        "\n",
        "def run_odt_and_draw_results(image_path, interpreter, threshold=0.5):\n",
        "  \"\"\"Run object detection on the input image and draw the detection results\"\"\"\n",
        "  # Load the input shape required by the model\n",
        "  _, input_height, input_width, _ = interpreter.get_input_details()[0]['shape']\n",
        "\n",
        "  # Load the input image and preprocess it\n",
        "  preprocessed_image, original_image = preprocess_image(\n",
        "      image_path,\n",
        "      (input_height, input_width)\n",
        "    )\n",
        "\n",
        "  # Run object detection on the input image\n",
        "  results = detect_objects(interpreter, preprocessed_image, threshold=threshold)\n",
        "\n",
        "  # Plot the detection results on the input image\n",
        "  original_image_np = original_image.numpy().astype(np.uint8)\n",
        "  for obj in results:\n",
        "    # Convert the object bounding box from relative coordinates to absolute\n",
        "    # coordinates based on the original image resolution\n",
        "    ymin, xmin, ymax, xmax = obj['bounding_box']\n",
        "    xmin = int(xmin * original_image_np.shape[1])\n",
        "    xmax = int(xmax * original_image_np.shape[1])\n",
        "    ymin = int(ymin * original_image_np.shape[0])\n",
        "    ymax = int(ymax * original_image_np.shape[0])\n",
        "\n",
        "    slope = findSampleSlope(original_image, xmin, ymin, xmax, ymax, 7)\n",
        "    if(slope == 100):\n",
        "      print(\"Fully vertical streak detected!!!\")\n",
        "    #print(\"Slope for streak with confidence: \" + str(obj['score']) + \"  :  \" + str(slope))\n",
        "\n",
        "    # Find the class index of the current object\n",
        "    class_id = int(obj['class_id'])\n",
        "\n",
        "    # Draw the bounding box and label on the image\n",
        "    color = [int(c) for c in COLORS[class_id]]\n",
        "    cv2.rectangle(original_image_np, (xmin, ymin), (xmax, ymax), color, 2)\n",
        "    # Make adjustments to make the label visible for all objects\n",
        "    y = ymin - 15 if ymin - 15 > 15 else ymin + 15\n",
        "    label = \"{}: {:.0f}% {}: {:.3f}\".format(classes[class_id], obj['score'] * 100, \"Slope\", slope)\n",
        "    cv2.putText(original_image_np, label, (xmin, y),\n",
        "        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "  # Return the final image\n",
        "  original_uint8 = original_image_np.astype(np.uint8)\n",
        "  return original_uint8\n"
      ],
      "metadata": {
        "id": "5DzuY7bIqvwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!rm ../tmp/image.png"
      ],
      "metadata": {
        "id": "ZjXnvDhIH6oA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#INPUT_IMAGE_URL = \"https://lh3.googleusercontent.com/fife/AAWUweXhiNM-Wjycs4I9azVLpApZIPTVlfYuEybDWngIaQzzJKwktIZMcNPfBCtuZF8-aZL9pX5F2HxKZDIn9GRbA6OH_Gqg3MEI3-twVk9mgJSlBSqs7Q1mPZu98L6EdrFTNhBgz9g8AS6Nahf4BrOLcYHq1vqPr4lUCq7CS2xAGcxhQ6bq85KtySX6l8zTkyJG7Dm5LL_tUH4mU4EguXcIy4s6ndN3irIXps53Cvu9ALO77Meig0xFS-ev63M4RFIyg98KwN6FyQiTlj4ul3EnePDG2SIoEWnnaau5dEHNBBfR5ggwmRs3Iv_gpJJf6V-DTzl8JL5SoZvP65JaFBI78MMZCrYk1IrXeawpTpTE-4Awv7kdn4SPokv2P9aT7m77fnCrJiMhraIUwchLkHh-KhQJvN1WH0evX2uQIxMsjYQBCs6sbintF2mIWCXRRPD4VrGQL5ziqP-PsgFteKFP7oWyWTDW7Yt6_FVTTWxxXBVUZRhcv8xfMogzf9l7NaUrZRAo5zlrGG6uSI5niGEmaCj-HqM99D5m9G3QK_vsNxIr1aZUXRhaMseLOXaFrxEE8ZxQiIGLX4mNzLb0X4GWWXBKR7il8VqFKNcqhaX1N6Asgex9FQLLsa87iqCS352sJ7640B0YUCv-B1F91_BTjuj4IwwGxUjtS9avSVhJzRVNqh3lEF4_4wD89oP5jgWaUAAwenRKIZ-eT8lAe403wGTLsTF19nrkkJxJyxLFrt-JTiP0uGyD_P7nIIbWTkpd196kY2iEB2B0zlJGahWGFoRPg5BIhU8jG8d_tbdBV9dn77il_VTgZgk_fg2yRh7O9V_VJ_ox1nHZSAZ73AZDJS6MuW9bqNRpUy24eg2nEJPvOmPro4mKBoKitHAeEEC0LlABW7H_tzS0yQoe9DZYVS9XHGgVuWqzrkKGN4j7O4s9S92-wF44okHuwWWevHSU4wBUC3tChArSC9u_BuBIGsdigx1FwhV1vz72F0zl0oPzNT9CRITkYSf7ey1vULl9X5JF2jYUpKtDrplDnEDjEP49v8fqhMdF-G7vQRYzR_VB0CnnOxXvhCfjca2BP4ScgCb20tkpR_kFCkkA6tx5V1Du3k0u3_sd5T6n-a7A9L9YytyeeSysq02PXcfYYtjZDhKbtGdEfL8bMcAQav31vZlxr-Nt1ZyKeYARehPMCkhxIiWIFIi-9LAMcQC3MF6DqWLRzqlksJi8aUhZWreAISxs0rN83d_VgY3cWk3bLGTRw6SopWbQn1PGLvTQrrNaCaZJy8AajYyjdK8xGdiV4M53Xsq2GgNJO8_JracsKIFJsYBOV-qNNuYys8ISeJnUqlELwBVRJnFqh7E3A1cWgz8RLomnC6OIAOLPL3mk4gn-KmxrfATAcdJB_6g9dRn6CPxM-Eb7UFtmP9y0XXVsyxLT9jlpPhooCabvMieDQmjWHaSIbbURsVJpAJ42Q8DSBX5lB-qpAwHBN8-bPVgNhflbYUJ0gCFNIsPOz14DsZXJGlA5NWcu3OTjqgGPePnVfqK2DCTa36AVKjgogELBTq68QvMO5XNs5SbzOoj-oHwalshfi48iCoag1H4DwQZgvBZYV_AsYOemqGgvYEi1cVvDt-2gWPZdwBLngyZTAjQxj6KY1Z3y6C9mZROn4lzrxoN83jNFpUEir7WUlT0w_fBegzncvJzAgjFZq3AtsdENSd4yqWGTQ5cMW5Qay4Kq7t7zukQlH30owKEx8EX4iidImc8GBD_0nyGfdELuJvl4Z90OWzbqC8ASsseWz3WQw35dQ0SiVSAVw_94e-yXaKaxC93WGv5UQStxxSJLxF6gfvt1r1FyNvimHoHsp3CdOA4_3S0IPChHPF1ZiTJtfmMApfbgF1GI3DCxSg4w4fpZFd1RlAWNW9GVWZWeQxf0qfcwVjh0sFJQ3eZ3yfuyrDMmcgSf0jKJEIQF_wnMhfrTe8qiE3UIoHMa5BO-HCs5CCz9veHdZ2YiZsj41TefcDeNX6bPeCl2xoNw3x_Iy_V-dT30n0mxZO5n-iC6_5DQp9iFxD5SfJOWFQrDd-okbM3tRMSw3HF-zsWFzctbz8O6q7-I4GmMYdonsuWKU6JMTVDLe-DQYLzVCVKc9kbpIU5zTREBCHw6phcllawlGOhaAaEhU-6bmRhVq5N5MzvCCsmpcy0Mr4EYj5I3XIOlR9mEVh3THscDg7cxKQDaWMRPsCrf-xONmhqTW9GXhISkpqpS4-yKTjEhkbls08ybkK5nkJOf7bx389mmXHzDy9xl3LVdHVF2LQagc7HbCv2Up2qlO9Ralj8GNU_9oibWWPDeggfM5lpWY7Sr1uegOgoZHjDq_ezavy6LEhzpGpDdf8o_VMaLFozb50Or99qyry4HXkRfhVsnfmLZPN0jJITZKhrh_E03WrfHyiDkwGpaMCaqbQvKGGiKUpwpRfo4YdYmQRCZ0mUUJRCuZcKv_yLGsOMltzw2XL23yaflD5EG2_9YNsdfiyR3slD3Y-FVHMXIn_nkmXqyvpI-FhF3rTsjr6s5qySEigKtDW1oYhdxWPciqgXkK-xxYIKVTEMX5I8L0shC-LXjouTgDC7GYaRGu376kp_3mKKOwZ-BxsEUsD9ygLu3XoHqBM8qM8oqfcUTHPjOcWPV29TaGKsUM8aptQIwYCq1syIB1_3ERc-hjdKZou-d4OY2iYKlmbGFcuOQ4Ws4dwMukqDdd_PX5-vPUY9pCZtgRPqb21mNUpHxlVeZjGCBi71uAolZFLyPz12-GR7V8TC8wxEInmMrNum70AfTrmELZijA1uj3_Em8LTo62v3h4Y3BQzuPNkD2K8snj8B0hwfyhzAkuQ_sRbaWHsGJDrMkpjVqHOen9SBxBp9KJYtFAQNCFtK3aKH0ZjjEdjoPs9EH8XmKK9hZFmi95w2zkL1h9pz8SwYFbN7ChRdY4GdD7JtG0c4MnHCOtKcquoHkbnPDTM_tX8wfa9uJXRTwUZyOA1XSvgRVTsyLBirDea8EnyzUrAt-YlppaANu2Sd5pH7djT3yjRIr_X8HOQxqs6sX1fenJcCjg8KqR1BeNZ0mHu857ob-1vhtzvpr2NQW83LeLCxKVbkLYsR8EmJ5QtK9qDOMCNJSbfW9HSy1qg90C-qF3UAtHs7-xysaKVFQoBWIhx5m2CEqpEm88ibTUofx85EFqlQKTr-aC97hCJRmKmxDlwsfvKdhlScPuNEHIchhzqoq0nIeMDBcFBYxs4JbzOQb-ur0CXvUS64SDC-k1eFS1jEwCDuHABhruF3JrnnXd4vsdUIn9j7D1FIqv40jIkuh6yYjg3xGUr9a5zkcZRcbboXqPKc4EvsZb5Jqi-W72gcPr2vxY5zPb1XPRPwTx0MAie3wSjtUikvZIN3o8D2MZl5disHZ9hipqya4l1ZWOnwZLoaCIkUm86QJK6KP67PgGy4CedIxcrvyrnMUyszEw_iuMQJdOnvx4VpF7SUzJDYnIBZiR4x2bSzKz42ox9QPQeDdNsE2TuVDaEjuxvPRvcuNlMTsnr-zo6XLXlXk9uYkTKXRjz72Bg-hn4kEJnDvkB0y1NUQjOsACZTAk-hA4x-qZhzxSl9TJcl-ajBYoJOz6hHvHjcFxBCjJLXsjh4LAmPe_bsstOCzTFXX7wsoo6yoNnsTBz3iigTConWqi7O9TiTqfjQkVc6k1Taoh6_NNpnZMUPI6JHAhWfY91mDLGzd-RMT2GQvPX8nRhNYvPdYpFrPIJB9VWQO5fvNVH6QHDBIEumaGBDmanL-zwFmtOOjHAi6wMz_p_1N3aZHFiw6uPxcGuP0T2M7E2IHrzbT4PlcGX7meuw2J4mtThkVavKlMvGwXQLo9jCQiXiPIg4gxbuMhlueCpdoNRGPzoFE0Q=s1920-w1920-h1200-no?authuser=1\"\n",
        "DETECTION_THRESHOLD = 0.45\n",
        "TEMP_FILE = 'Flake000016_Cam1_2_2022-1-28-23-43-5-821.png'\n",
        "\n",
        "#!wget -q -O $TEMP_FILE $INPUT_IMAGE_URL\n",
        "#im = Image.open(TEMP_FILE)\n",
        "#im.thumbnail((1920, 1200), Image.ANTIALIAS)\n",
        "#im.save(TEMP_FILE, 'PNG')\n",
        "\n",
        "# Load the TFLite model\n",
        "interpreter = tf.lite.Interpreter(model_path=model_path)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Run inference and draw detection result on the local copy of the original file\n",
        "detection_result_image = run_odt_and_draw_results(\n",
        "    TEMP_FILE,\n",
        "    interpreter,\n",
        "    threshold=DETECTION_THRESHOLD\n",
        ")\n",
        "\n",
        "# Show the detection result\n",
        "Image.fromarray(detection_result_image)\n"
      ],
      "metadata": {
        "id": "9z7OIt_kq0gQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Leftovers"
      ],
      "metadata": {
        "id": "UejLtdIEa1PX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Unused at the moment (everything below this cell, and in it)****************************\n",
        "\n",
        "\n",
        "# Load the TFLite model and allocate tensors.\n",
        "interpreter = tf.lite.Interpreter(model_path=\"model.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output tensors.\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# Test the model on random input data.\n",
        "input_shape = input_details[0]['shape']\n",
        "input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
        "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "\n",
        "interpreter.invoke()\n",
        "\n",
        "# The function `get_tensor()` returns a copy of the tensor data.\n",
        "# Use `tensor()` in order to get a pointer to the tensor.\n",
        "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "print(output_data)\n"
      ],
      "metadata": {
        "id": "sLyzjZ48p0d8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Mount google drive for exports"
      ],
      "metadata": {
        "id": "YBhWyEhr2q0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#link drive for easy saving, although just downloading the model is easier\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "5weWv68yCFv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Playground\n",
        "\n"
      ],
      "metadata": {
        "id": "hcV-UjSo-REo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Helper function for drawing a bounded box on an image\n",
        "def draw_rect(image, box):\n",
        "    y_min = int(max(1, (box[0] * image.height)))\n",
        "    x_min = int(max(1, (box[1] * image.width)))\n",
        "    y_max = int(min(image.height, (box[2] * image.height)))\n",
        "    x_max = int(min(image.width, (box[3] * image.width)))\n",
        "    \n",
        "    # draw a rectangle on the image\n",
        "    cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (255, 255, 255), 2)"
      ],
      "metadata": {
        "id": "ri3QSSAf-XMC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}